{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qZY0SdTeE21",
        "outputId": "d1e3cce5-f83e-4d3e-ff17-246dc31014ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.10.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "\n",
        "from timeit import default_timer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Conv2D, BatchNormalization, Dense, Flatten, Reshape\n",
        "import tensorflow as tf\n",
        "from google.colab import userdata\n",
        "import os\n",
        "!pip install keras --upgrade\n",
        "!pip install datasets\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "from keras import models, callbacks, utils\n",
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "from tqdm.auto import trange\n",
        "\n",
        "from keras import models, utils\n",
        "from huggingface_hub import hf_hub_download\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pR8K7wAx5ct",
        "outputId": "d2c912cd-ffe2-4603-ce35-fa927deff511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n",
            "Downloading 3-million-sudoku-puzzles-with-ratings.zip to /content\n",
            " 94% 195M/207M [00:02<00:00, 99.6MB/s]\n",
            "100% 207M/207M [00:02<00:00, 75.7MB/s]\n",
            "Archive:  3-million-sudoku-puzzles-with-ratings.zip\n",
            "  inflating: sudoku-3m.csv           \n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Please uncomment those lines if you are running this code on Google Colab\n",
        "Else if you are running this code on your local machine, please use this dataset \n",
        "https://www.kaggle.com/datasets/radcliffe/3-million-sudoku-puzzles-with-ratings\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "!pip install kaggle\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "!kaggle datasets download -d radcliffe/3-million-sudoku-puzzles-with-ratings\n",
        "!unzip 3-million-sudoku-puzzles-with-ratings.zip \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the data and pre processed it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "qG_si6DoyBCa"
      },
      "outputs": [],
      "source": [
        "# Read the dataset\n",
        "data = pd.read_csv(\"sudoku-3m.csv\", skiprows=lambda i: i % 10 != 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLr0Au5Sdz0E",
        "outputId": "328d867e-d132-46d6-9485-8305ff574549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(300000, 5)\n"
          ]
        }
      ],
      "source": [
        "print(data.shape) # Display the number of samples and features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx92Oh_Qxvlz",
        "outputId": "fda99293-accf-4075-8f75-00cbaac3ebb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 7 5 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [2 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 9 0 0]\n",
            " [2 0 0 ... 0 4 0]\n",
            " [7 0 4 ... 0 4 7]]\n"
          ]
        }
      ],
      "source": [
        "def preprocess_data(data):\n",
        "    # Replace periods with zeros in puzzle strings\n",
        "    data['puzzle'] = data['puzzle'].str.replace('.', '0')\n",
        "\n",
        "    # Extract Sudoku grid values (first 81 characters of the puzzle string)\n",
        "    X = np.array([list(map(int, puzzle[:81])) for puzzle in data['puzzle']])\n",
        "    print(X)\n",
        "    y = data['solution'].values  # No need to adjust targets here\n",
        "\n",
        "    # Reshape X to have dimensions (num_samples, 9, 9, 1)\n",
        "    X = X.reshape(-1, 9, 9, 1)\n",
        "\n",
        "    # Normalize input\n",
        "    X = X / 9.0  # Sudoku values range from 1 to 9\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "X, y = preprocess_data(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "GD_WZKK4-FFx"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train = np.eye(10)[X_train.reshape(-1).astype(int)].reshape(X_train.shape[0], 9, 9, 10)\n",
        "X_test = np.eye(10)[X_test.reshape(-1).astype(int)].reshape(X_test.shape[0], 9, 9, 10)\n",
        "y_train = np.array([list(map(int, y)) for y in y_train]).reshape(y_train.shape[0], -1) - 1\n",
        "y_test = np.array([list(map(int, y)) for y in y_test]).reshape(y_test.shape[0], -1) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzZoKRBIsZqc",
        "outputId": "c010eede-aa7a-4772-e4f1-5c9d7ec6f3a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Apr  8 17:11:54 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0              32W /  70W |   2503MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi # Display the GPU information, be sure to run this code if you are on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Now that we have our data and pre processed it, we can define our model and train it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV7DPbPwWT1n",
        "outputId": "9de0f2ea-766a-4763-d8d3-8b8d72e9e72b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:576: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 12ms/step - loss: 209315.3125 - position_1_1_accuracy: 0.1125 - position_1_2_accuracy: 0.1115 - position_1_3_accuracy: 0.1131 - position_1_4_accuracy: 0.1095 - position_1_5_accuracy: 0.1119 - position_1_6_accuracy: 0.1103 - position_1_7_accuracy: 0.1120 - position_1_8_accuracy: 0.1130 - position_1_9_accuracy: 0.1113 - val_loss: 988767.5625 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1129 - val_position_1_3_accuracy: 0.1140 - val_position_1_4_accuracy: 0.1120 - val_position_1_5_accuracy: 0.1101 - val_position_1_6_accuracy: 0.1132 - val_position_1_7_accuracy: 0.1130 - val_position_1_8_accuracy: 0.1104 - val_position_1_9_accuracy: 0.1148\n",
            "Epoch 2/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - loss: 2293447.5000 - position_1_1_accuracy: 0.1101 - position_1_2_accuracy: 0.1093 - position_1_3_accuracy: 0.1125 - position_1_4_accuracy: 0.1109 - position_1_5_accuracy: 0.1099 - position_1_6_accuracy: 0.1106 - position_1_7_accuracy: 0.1131 - position_1_8_accuracy: 0.1106 - position_1_9_accuracy: 0.1118 - val_loss: 2985951.5000 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1129 - val_position_1_3_accuracy: 0.1120 - val_position_1_4_accuracy: 0.1127 - val_position_1_5_accuracy: 0.1129 - val_position_1_6_accuracy: 0.1118 - val_position_1_7_accuracy: 0.1128 - val_position_1_8_accuracy: 0.1096 - val_position_1_9_accuracy: 0.1148\n",
            "Epoch 3/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 5650990.0000 - position_1_1_accuracy: 0.1119 - position_1_2_accuracy: 0.1120 - position_1_3_accuracy: 0.1105 - position_1_4_accuracy: 0.1108 - position_1_5_accuracy: 0.1113 - position_1_6_accuracy: 0.1102 - position_1_7_accuracy: 0.1110 - position_1_8_accuracy: 0.1121 - position_1_9_accuracy: 0.1114 - val_loss: 4610553.5000 - val_position_1_1_accuracy: 0.1091 - val_position_1_2_accuracy: 0.1125 - val_position_1_3_accuracy: 0.1122 - val_position_1_4_accuracy: 0.1095 - val_position_1_5_accuracy: 0.1129 - val_position_1_6_accuracy: 0.1130 - val_position_1_7_accuracy: 0.1130 - val_position_1_8_accuracy: 0.1104 - val_position_1_9_accuracy: 0.1092\n",
            "Epoch 4/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 10074687.0000 - position_1_1_accuracy: 0.1111 - position_1_2_accuracy: 0.1106 - position_1_3_accuracy: 0.1107 - position_1_4_accuracy: 0.1096 - position_1_5_accuracy: 0.1103 - position_1_6_accuracy: 0.1109 - position_1_7_accuracy: 0.1116 - position_1_8_accuracy: 0.1115 - position_1_9_accuracy: 0.1115 - val_loss: 7657995.0000 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1103 - val_position_1_3_accuracy: 0.1132 - val_position_1_4_accuracy: 0.1127 - val_position_1_5_accuracy: 0.1129 - val_position_1_6_accuracy: 0.1064 - val_position_1_7_accuracy: 0.1130 - val_position_1_8_accuracy: 0.1118 - val_position_1_9_accuracy: 0.1125\n",
            "Epoch 5/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 15430924.0000 - position_1_1_accuracy: 0.1108 - position_1_2_accuracy: 0.1120 - position_1_3_accuracy: 0.1114 - position_1_4_accuracy: 0.1127 - position_1_5_accuracy: 0.1100 - position_1_6_accuracy: 0.1106 - position_1_7_accuracy: 0.1106 - position_1_8_accuracy: 0.1105 - position_1_9_accuracy: 0.1119 - val_loss: 11002020.0000 - val_position_1_1_accuracy: 0.1140 - val_position_1_2_accuracy: 0.1044 - val_position_1_3_accuracy: 0.1122 - val_position_1_4_accuracy: 0.1127 - val_position_1_5_accuracy: 0.1129 - val_position_1_6_accuracy: 0.1130 - val_position_1_7_accuracy: 0.1072 - val_position_1_8_accuracy: 0.1126 - val_position_1_9_accuracy: 0.1125\n",
            "Epoch 6/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 21603260.0000 - position_1_1_accuracy: 0.1099 - position_1_2_accuracy: 0.1119 - position_1_3_accuracy: 0.1113 - position_1_4_accuracy: 0.1112 - position_1_5_accuracy: 0.1113 - position_1_6_accuracy: 0.1097 - position_1_7_accuracy: 0.1122 - position_1_8_accuracy: 0.1113 - position_1_9_accuracy: 0.1111 - val_loss: 14907902.0000 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1082 - val_position_1_3_accuracy: 0.1089 - val_position_1_4_accuracy: 0.1067 - val_position_1_5_accuracy: 0.1129 - val_position_1_6_accuracy: 0.1118 - val_position_1_7_accuracy: 0.1132 - val_position_1_8_accuracy: 0.1119 - val_position_1_9_accuracy: 0.1092\n",
            "Epoch 7/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 28745840.0000 - position_1_1_accuracy: 0.1124 - position_1_2_accuracy: 0.1123 - position_1_3_accuracy: 0.1112 - position_1_4_accuracy: 0.1097 - position_1_5_accuracy: 0.1127 - position_1_6_accuracy: 0.1106 - position_1_7_accuracy: 0.1131 - position_1_8_accuracy: 0.1097 - position_1_9_accuracy: 0.1112 - val_loss: 14475842.0000 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1044 - val_position_1_3_accuracy: 0.1117 - val_position_1_4_accuracy: 0.1063 - val_position_1_5_accuracy: 0.1085 - val_position_1_6_accuracy: 0.1112 - val_position_1_7_accuracy: 0.1141 - val_position_1_8_accuracy: 0.1119 - val_position_1_9_accuracy: 0.1092\n",
            "Epoch 8/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 36516412.0000 - position_1_1_accuracy: 0.1095 - position_1_2_accuracy: 0.1128 - position_1_3_accuracy: 0.1113 - position_1_4_accuracy: 0.1114 - position_1_5_accuracy: 0.1114 - position_1_6_accuracy: 0.1103 - position_1_7_accuracy: 0.1092 - position_1_8_accuracy: 0.1111 - position_1_9_accuracy: 0.1116 - val_loss: 20744280.0000 - val_position_1_1_accuracy: 0.1084 - val_position_1_2_accuracy: 0.1044 - val_position_1_3_accuracy: 0.1132 - val_position_1_4_accuracy: 0.1059 - val_position_1_5_accuracy: 0.1105 - val_position_1_6_accuracy: 0.1130 - val_position_1_7_accuracy: 0.1141 - val_position_1_8_accuracy: 0.1126 - val_position_1_9_accuracy: 0.1128\n",
            "Epoch 9/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 45642580.0000 - position_1_1_accuracy: 0.1108 - position_1_2_accuracy: 0.1105 - position_1_3_accuracy: 0.1128 - position_1_4_accuracy: 0.1117 - position_1_5_accuracy: 0.1113 - position_1_6_accuracy: 0.1110 - position_1_7_accuracy: 0.1105 - position_1_8_accuracy: 0.1110 - position_1_9_accuracy: 0.1107 - val_loss: 27147392.0000 - val_position_1_1_accuracy: 0.1106 - val_position_1_2_accuracy: 0.1082 - val_position_1_3_accuracy: 0.1099 - val_position_1_4_accuracy: 0.1127 - val_position_1_5_accuracy: 0.1129 - val_position_1_6_accuracy: 0.1104 - val_position_1_7_accuracy: 0.1130 - val_position_1_8_accuracy: 0.1118 - val_position_1_9_accuracy: 0.1068\n",
            "Epoch 10/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 55215948.0000 - position_1_1_accuracy: 0.1111 - position_1_2_accuracy: 0.1106 - position_1_3_accuracy: 0.1121 - position_1_4_accuracy: 0.1112 - position_1_5_accuracy: 0.1080 - position_1_6_accuracy: 0.1116 - position_1_7_accuracy: 0.1099 - position_1_8_accuracy: 0.1125 - position_1_9_accuracy: 0.1102 - val_loss: 31755458.0000 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1103 - val_position_1_3_accuracy: 0.1109 - val_position_1_4_accuracy: 0.1127 - val_position_1_5_accuracy: 0.1130 - val_position_1_6_accuracy: 0.1130 - val_position_1_7_accuracy: 0.1135 - val_position_1_8_accuracy: 0.1109 - val_position_1_9_accuracy: 0.1148\n",
            "Epoch 11/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 65876780.0000 - position_1_1_accuracy: 0.1089 - position_1_2_accuracy: 0.1105 - position_1_3_accuracy: 0.1093 - position_1_4_accuracy: 0.1117 - position_1_5_accuracy: 0.1108 - position_1_6_accuracy: 0.1113 - position_1_7_accuracy: 0.1118 - position_1_8_accuracy: 0.1094 - position_1_9_accuracy: 0.1109 - val_loss: 34980560.0000 - val_position_1_1_accuracy: 0.1100 - val_position_1_2_accuracy: 0.1125 - val_position_1_3_accuracy: 0.1108 - val_position_1_4_accuracy: 0.1095 - val_position_1_5_accuracy: 0.1126 - val_position_1_6_accuracy: 0.1125 - val_position_1_7_accuracy: 0.1133 - val_position_1_8_accuracy: 0.1096 - val_position_1_9_accuracy: 0.1068\n",
            "Epoch 12/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 77203056.0000 - position_1_1_accuracy: 0.1109 - position_1_2_accuracy: 0.1115 - position_1_3_accuracy: 0.1127 - position_1_4_accuracy: 0.1097 - position_1_5_accuracy: 0.1107 - position_1_6_accuracy: 0.1118 - position_1_7_accuracy: 0.1135 - position_1_8_accuracy: 0.1124 - position_1_9_accuracy: 0.1104 - val_loss: 46380080.0000 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1130 - val_position_1_3_accuracy: 0.1108 - val_position_1_4_accuracy: 0.1127 - val_position_1_5_accuracy: 0.1129 - val_position_1_6_accuracy: 0.1130 - val_position_1_7_accuracy: 0.1083 - val_position_1_8_accuracy: 0.1119 - val_position_1_9_accuracy: 0.1092\n",
            "Epoch 13/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 90043088.0000 - position_1_1_accuracy: 0.1117 - position_1_2_accuracy: 0.1100 - position_1_3_accuracy: 0.1127 - position_1_4_accuracy: 0.1107 - position_1_5_accuracy: 0.1114 - position_1_6_accuracy: 0.1112 - position_1_7_accuracy: 0.1133 - position_1_8_accuracy: 0.1112 - position_1_9_accuracy: 0.1114 - val_loss: 43579380.0000 - val_position_1_1_accuracy: 0.1084 - val_position_1_2_accuracy: 0.1082 - val_position_1_3_accuracy: 0.1107 - val_position_1_4_accuracy: 0.1112 - val_position_1_5_accuracy: 0.1099 - val_position_1_6_accuracy: 0.1132 - val_position_1_7_accuracy: 0.1133 - val_position_1_8_accuracy: 0.1138 - val_position_1_9_accuracy: 0.1148\n",
            "Epoch 14/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - loss: 102698568.0000 - position_1_1_accuracy: 0.1119 - position_1_2_accuracy: 0.1121 - position_1_3_accuracy: 0.1127 - position_1_4_accuracy: 0.1107 - position_1_5_accuracy: 0.1110 - position_1_6_accuracy: 0.1124 - position_1_7_accuracy: 0.1095 - position_1_8_accuracy: 0.1115 - position_1_9_accuracy: 0.1113 - val_loss: 59646000.0000 - val_position_1_1_accuracy: 0.1098 - val_position_1_2_accuracy: 0.1147 - val_position_1_3_accuracy: 0.1108 - val_position_1_4_accuracy: 0.1134 - val_position_1_5_accuracy: 0.1130 - val_position_1_6_accuracy: 0.1124 - val_position_1_7_accuracy: 0.1081 - val_position_1_8_accuracy: 0.1119 - val_position_1_9_accuracy: 0.1113\n",
            "Epoch 15/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 116515744.0000 - position_1_1_accuracy: 0.1104 - position_1_2_accuracy: 0.1112 - position_1_3_accuracy: 0.1116 - position_1_4_accuracy: 0.1120 - position_1_5_accuracy: 0.1105 - position_1_6_accuracy: 0.1109 - position_1_7_accuracy: 0.1126 - position_1_8_accuracy: 0.1107 - position_1_9_accuracy: 0.1108 - val_loss: 60160608.0000 - val_position_1_1_accuracy: 0.1084 - val_position_1_2_accuracy: 0.1103 - val_position_1_3_accuracy: 0.1089 - val_position_1_4_accuracy: 0.1071 - val_position_1_5_accuracy: 0.1126 - val_position_1_6_accuracy: 0.1124 - val_position_1_7_accuracy: 0.1072 - val_position_1_8_accuracy: 0.1109 - val_position_1_9_accuracy: 0.1092\n",
            "Epoch 16/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 130832312.0000 - position_1_1_accuracy: 0.1118 - position_1_2_accuracy: 0.1105 - position_1_3_accuracy: 0.1122 - position_1_4_accuracy: 0.1116 - position_1_5_accuracy: 0.1112 - position_1_6_accuracy: 0.1108 - position_1_7_accuracy: 0.1111 - position_1_8_accuracy: 0.1109 - position_1_9_accuracy: 0.1107 - val_loss: 75679840.0000 - val_position_1_1_accuracy: 0.1098 - val_position_1_2_accuracy: 0.1082 - val_position_1_3_accuracy: 0.1108 - val_position_1_4_accuracy: 0.1063 - val_position_1_5_accuracy: 0.1129 - val_position_1_6_accuracy: 0.1124 - val_position_1_7_accuracy: 0.1072 - val_position_1_8_accuracy: 0.1119 - val_position_1_9_accuracy: 0.1068\n",
            "Epoch 17/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 146851712.0000 - position_1_1_accuracy: 0.1111 - position_1_2_accuracy: 0.1110 - position_1_3_accuracy: 0.1121 - position_1_4_accuracy: 0.1106 - position_1_5_accuracy: 0.1113 - position_1_6_accuracy: 0.1126 - position_1_7_accuracy: 0.1102 - position_1_8_accuracy: 0.1098 - position_1_9_accuracy: 0.1119 - val_loss: 91102752.0000 - val_position_1_1_accuracy: 0.1106 - val_position_1_2_accuracy: 0.1106 - val_position_1_3_accuracy: 0.1120 - val_position_1_4_accuracy: 0.1112 - val_position_1_5_accuracy: 0.1101 - val_position_1_6_accuracy: 0.1132 - val_position_1_7_accuracy: 0.1007 - val_position_1_8_accuracy: 0.1110 - val_position_1_9_accuracy: 0.1117\n",
            "Epoch 18/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 164295984.0000 - position_1_1_accuracy: 0.1119 - position_1_2_accuracy: 0.1118 - position_1_3_accuracy: 0.1102 - position_1_4_accuracy: 0.1112 - position_1_5_accuracy: 0.1112 - position_1_6_accuracy: 0.1126 - position_1_7_accuracy: 0.1096 - position_1_8_accuracy: 0.1113 - position_1_9_accuracy: 0.1098 - val_loss: 84142056.0000 - val_position_1_1_accuracy: 0.1106 - val_position_1_2_accuracy: 0.1125 - val_position_1_3_accuracy: 0.1093 - val_position_1_4_accuracy: 0.1131 - val_position_1_5_accuracy: 0.1105 - val_position_1_6_accuracy: 0.1112 - val_position_1_7_accuracy: 0.1072 - val_position_1_8_accuracy: 0.1104 - val_position_1_9_accuracy: 0.1068\n",
            "Epoch 19/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 181387520.0000 - position_1_1_accuracy: 0.1125 - position_1_2_accuracy: 0.1112 - position_1_3_accuracy: 0.1113 - position_1_4_accuracy: 0.1124 - position_1_5_accuracy: 0.1116 - position_1_6_accuracy: 0.1096 - position_1_7_accuracy: 0.1124 - position_1_8_accuracy: 0.1105 - position_1_9_accuracy: 0.1112 - val_loss: 93921456.0000 - val_position_1_1_accuracy: 0.1106 - val_position_1_2_accuracy: 0.1103 - val_position_1_3_accuracy: 0.1122 - val_position_1_4_accuracy: 0.1128 - val_position_1_5_accuracy: 0.1101 - val_position_1_6_accuracy: 0.1130 - val_position_1_7_accuracy: 0.1133 - val_position_1_8_accuracy: 0.1121 - val_position_1_9_accuracy: 0.1085\n",
            "Epoch 20/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 198710128.0000 - position_1_1_accuracy: 0.1118 - position_1_2_accuracy: 0.1124 - position_1_3_accuracy: 0.1111 - position_1_4_accuracy: 0.1110 - position_1_5_accuracy: 0.1091 - position_1_6_accuracy: 0.1097 - position_1_7_accuracy: 0.1106 - position_1_8_accuracy: 0.1123 - position_1_9_accuracy: 0.1118 - val_loss: 93033696.0000 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1125 - val_position_1_3_accuracy: 0.1135 - val_position_1_4_accuracy: 0.1095 - val_position_1_5_accuracy: 0.1126 - val_position_1_6_accuracy: 0.1064 - val_position_1_7_accuracy: 0.1072 - val_position_1_8_accuracy: 0.1118 - val_position_1_9_accuracy: 0.1148\n",
            "Epoch 21/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 218036176.0000 - position_1_1_accuracy: 0.1118 - position_1_2_accuracy: 0.1116 - position_1_3_accuracy: 0.1123 - position_1_4_accuracy: 0.1103 - position_1_5_accuracy: 0.1107 - position_1_6_accuracy: 0.1095 - position_1_7_accuracy: 0.1113 - position_1_8_accuracy: 0.1112 - position_1_9_accuracy: 0.1116 - val_loss: 113659152.0000 - val_position_1_1_accuracy: 0.1091 - val_position_1_2_accuracy: 0.1046 - val_position_1_3_accuracy: 0.1132 - val_position_1_4_accuracy: 0.1095 - val_position_1_5_accuracy: 0.1129 - val_position_1_6_accuracy: 0.1088 - val_position_1_7_accuracy: 0.1130 - val_position_1_8_accuracy: 0.1160 - val_position_1_9_accuracy: 0.1113\n",
            "Epoch 22/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 238653408.0000 - position_1_1_accuracy: 0.1112 - position_1_2_accuracy: 0.1113 - position_1_3_accuracy: 0.1125 - position_1_4_accuracy: 0.1120 - position_1_5_accuracy: 0.1122 - position_1_6_accuracy: 0.1117 - position_1_7_accuracy: 0.1121 - position_1_8_accuracy: 0.1109 - position_1_9_accuracy: 0.1104 - val_loss: 116216776.0000 - val_position_1_1_accuracy: 0.1140 - val_position_1_2_accuracy: 0.1156 - val_position_1_3_accuracy: 0.1071 - val_position_1_4_accuracy: 0.1140 - val_position_1_5_accuracy: 0.1105 - val_position_1_6_accuracy: 0.1129 - val_position_1_7_accuracy: 0.1130 - val_position_1_8_accuracy: 0.1118 - val_position_1_9_accuracy: 0.1117\n",
            "Epoch 23/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 258588272.0000 - position_1_1_accuracy: 0.1091 - position_1_2_accuracy: 0.1110 - position_1_3_accuracy: 0.1112 - position_1_4_accuracy: 0.1102 - position_1_5_accuracy: 0.1118 - position_1_6_accuracy: 0.1114 - position_1_7_accuracy: 0.1100 - position_1_8_accuracy: 0.1111 - position_1_9_accuracy: 0.1115 - val_loss: 141281184.0000 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1106 - val_position_1_3_accuracy: 0.1112 - val_position_1_4_accuracy: 0.1095 - val_position_1_5_accuracy: 0.1085 - val_position_1_6_accuracy: 0.1132 - val_position_1_7_accuracy: 0.1128 - val_position_1_8_accuracy: 0.1159 - val_position_1_9_accuracy: 0.1068\n",
            "Epoch 24/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - loss: 279825984.0000 - position_1_1_accuracy: 0.1108 - position_1_2_accuracy: 0.1109 - position_1_3_accuracy: 0.1094 - position_1_4_accuracy: 0.1095 - position_1_5_accuracy: 0.1118 - position_1_6_accuracy: 0.1114 - position_1_7_accuracy: 0.1093 - position_1_8_accuracy: 0.1092 - position_1_9_accuracy: 0.1102 - val_loss: 130422088.0000 - val_position_1_1_accuracy: 0.1133 - val_position_1_2_accuracy: 0.1134 - val_position_1_3_accuracy: 0.1115 - val_position_1_4_accuracy: 0.1120 - val_position_1_5_accuracy: 0.1118 - val_position_1_6_accuracy: 0.1112 - val_position_1_7_accuracy: 0.1141 - val_position_1_8_accuracy: 0.1104 - val_position_1_9_accuracy: 0.1125\n",
            "Epoch 25/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 300334688.0000 - position_1_1_accuracy: 0.1097 - position_1_2_accuracy: 0.1114 - position_1_3_accuracy: 0.1113 - position_1_4_accuracy: 0.1110 - position_1_5_accuracy: 0.1113 - position_1_6_accuracy: 0.1107 - position_1_7_accuracy: 0.1118 - position_1_8_accuracy: 0.1097 - position_1_9_accuracy: 0.1107 - val_loss: 146781008.0000 - val_position_1_1_accuracy: 0.1091 - val_position_1_2_accuracy: 0.1103 - val_position_1_3_accuracy: 0.1117 - val_position_1_4_accuracy: 0.1120 - val_position_1_5_accuracy: 0.1129 - val_position_1_6_accuracy: 0.1124 - val_position_1_7_accuracy: 0.1133 - val_position_1_8_accuracy: 0.1109 - val_position_1_9_accuracy: 0.1128\n",
            "Epoch 26/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 323881728.0000 - position_1_1_accuracy: 0.1119 - position_1_2_accuracy: 0.1127 - position_1_3_accuracy: 0.1113 - position_1_4_accuracy: 0.1100 - position_1_5_accuracy: 0.1115 - position_1_6_accuracy: 0.1092 - position_1_7_accuracy: 0.1104 - position_1_8_accuracy: 0.1099 - position_1_9_accuracy: 0.1129 - val_loss: 155875936.0000 - val_position_1_1_accuracy: 0.1091 - val_position_1_2_accuracy: 0.1106 - val_position_1_3_accuracy: 0.1132 - val_position_1_4_accuracy: 0.1125 - val_position_1_5_accuracy: 0.1099 - val_position_1_6_accuracy: 0.1129 - val_position_1_7_accuracy: 0.1141 - val_position_1_8_accuracy: 0.1072 - val_position_1_9_accuracy: 0.1114\n",
            "Epoch 27/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 349727008.0000 - position_1_1_accuracy: 0.1112 - position_1_2_accuracy: 0.1121 - position_1_3_accuracy: 0.1103 - position_1_4_accuracy: 0.1102 - position_1_5_accuracy: 0.1116 - position_1_6_accuracy: 0.1113 - position_1_7_accuracy: 0.1098 - position_1_8_accuracy: 0.1105 - position_1_9_accuracy: 0.1107 - val_loss: 162318736.0000 - val_position_1_1_accuracy: 0.1133 - val_position_1_2_accuracy: 0.1147 - val_position_1_3_accuracy: 0.1117 - val_position_1_4_accuracy: 0.1146 - val_position_1_5_accuracy: 0.1118 - val_position_1_6_accuracy: 0.1088 - val_position_1_7_accuracy: 0.1099 - val_position_1_8_accuracy: 0.1072 - val_position_1_9_accuracy: 0.1125\n",
            "Epoch 28/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 372042304.0000 - position_1_1_accuracy: 0.1121 - position_1_2_accuracy: 0.1107 - position_1_3_accuracy: 0.1117 - position_1_4_accuracy: 0.1116 - position_1_5_accuracy: 0.1116 - position_1_6_accuracy: 0.1107 - position_1_7_accuracy: 0.1099 - position_1_8_accuracy: 0.1106 - position_1_9_accuracy: 0.1102 - val_loss: 182402544.0000 - val_position_1_1_accuracy: 0.1084 - val_position_1_2_accuracy: 0.1105 - val_position_1_3_accuracy: 0.1107 - val_position_1_4_accuracy: 0.1135 - val_position_1_5_accuracy: 0.1099 - val_position_1_6_accuracy: 0.1124 - val_position_1_7_accuracy: 0.1083 - val_position_1_8_accuracy: 0.1096 - val_position_1_9_accuracy: 0.1092\n",
            "Epoch 29/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 398319808.0000 - position_1_1_accuracy: 0.1122 - position_1_2_accuracy: 0.1126 - position_1_3_accuracy: 0.1100 - position_1_4_accuracy: 0.1099 - position_1_5_accuracy: 0.1107 - position_1_6_accuracy: 0.1094 - position_1_7_accuracy: 0.1106 - position_1_8_accuracy: 0.1111 - position_1_9_accuracy: 0.1108 - val_loss: 220448256.0000 - val_position_1_1_accuracy: 0.1098 - val_position_1_2_accuracy: 0.1082 - val_position_1_3_accuracy: 0.1122 - val_position_1_4_accuracy: 0.1127 - val_position_1_5_accuracy: 0.1099 - val_position_1_6_accuracy: 0.1064 - val_position_1_7_accuracy: 0.1133 - val_position_1_8_accuracy: 0.1138 - val_position_1_9_accuracy: 0.1117\n",
            "Epoch 30/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 422344288.0000 - position_1_1_accuracy: 0.1098 - position_1_2_accuracy: 0.1114 - position_1_3_accuracy: 0.1105 - position_1_4_accuracy: 0.1116 - position_1_5_accuracy: 0.1105 - position_1_6_accuracy: 0.1117 - position_1_7_accuracy: 0.1102 - position_1_8_accuracy: 0.1094 - position_1_9_accuracy: 0.1090 - val_loss: 202981184.0000 - val_position_1_1_accuracy: 0.1134 - val_position_1_2_accuracy: 0.1125 - val_position_1_3_accuracy: 0.1108 - val_position_1_4_accuracy: 0.1095 - val_position_1_5_accuracy: 0.1085 - val_position_1_6_accuracy: 0.1132 - val_position_1_7_accuracy: 0.1083 - val_position_1_8_accuracy: 0.1192 - val_position_1_9_accuracy: 0.1092\n",
            "Epoch 31/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 451001664.0000 - position_1_1_accuracy: 0.1107 - position_1_2_accuracy: 0.1111 - position_1_3_accuracy: 0.1116 - position_1_4_accuracy: 0.1100 - position_1_5_accuracy: 0.1123 - position_1_6_accuracy: 0.1117 - position_1_7_accuracy: 0.1094 - position_1_8_accuracy: 0.1115 - position_1_9_accuracy: 0.1112 - val_loss: 248395840.0000 - val_position_1_1_accuracy: 0.1098 - val_position_1_2_accuracy: 0.1082 - val_position_1_3_accuracy: 0.1132 - val_position_1_4_accuracy: 0.1063 - val_position_1_5_accuracy: 0.1100 - val_position_1_6_accuracy: 0.1135 - val_position_1_7_accuracy: 0.1130 - val_position_1_8_accuracy: 0.1118 - val_position_1_9_accuracy: 0.1092\n",
            "Epoch 32/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 7ms/step - loss: 477744992.0000 - position_1_1_accuracy: 0.1104 - position_1_2_accuracy: 0.1115 - position_1_3_accuracy: 0.1098 - position_1_4_accuracy: 0.1112 - position_1_5_accuracy: 0.1098 - position_1_6_accuracy: 0.1111 - position_1_7_accuracy: 0.1113 - position_1_8_accuracy: 0.1108 - position_1_9_accuracy: 0.1097 - val_loss: 252785232.0000 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1129 - val_position_1_3_accuracy: 0.1107 - val_position_1_4_accuracy: 0.1101 - val_position_1_5_accuracy: 0.1126 - val_position_1_6_accuracy: 0.1088 - val_position_1_7_accuracy: 0.1132 - val_position_1_8_accuracy: 0.1072 - val_position_1_9_accuracy: 0.1138\n",
            "Epoch 33/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 506338944.0000 - position_1_1_accuracy: 0.1108 - position_1_2_accuracy: 0.1100 - position_1_3_accuracy: 0.1125 - position_1_4_accuracy: 0.1112 - position_1_5_accuracy: 0.1110 - position_1_6_accuracy: 0.1111 - position_1_7_accuracy: 0.1098 - position_1_8_accuracy: 0.1102 - position_1_9_accuracy: 0.1108 - val_loss: 239892704.0000 - val_position_1_1_accuracy: 0.1084 - val_position_1_2_accuracy: 0.1106 - val_position_1_3_accuracy: 0.1171 - val_position_1_4_accuracy: 0.1115 - val_position_1_5_accuracy: 0.1101 - val_position_1_6_accuracy: 0.1064 - val_position_1_7_accuracy: 0.1141 - val_position_1_8_accuracy: 0.1126 - val_position_1_9_accuracy: 0.1113\n",
            "Epoch 34/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 538519680.0000 - position_1_1_accuracy: 0.1096 - position_1_2_accuracy: 0.1115 - position_1_3_accuracy: 0.1121 - position_1_4_accuracy: 0.1109 - position_1_5_accuracy: 0.1101 - position_1_6_accuracy: 0.1107 - position_1_7_accuracy: 0.1108 - position_1_8_accuracy: 0.1100 - position_1_9_accuracy: 0.1103 - val_loss: 286372032.0000 - val_position_1_1_accuracy: 0.1053 - val_position_1_2_accuracy: 0.1103 - val_position_1_3_accuracy: 0.1117 - val_position_1_4_accuracy: 0.1095 - val_position_1_5_accuracy: 0.1085 - val_position_1_6_accuracy: 0.1064 - val_position_1_7_accuracy: 0.1132 - val_position_1_8_accuracy: 0.1128 - val_position_1_9_accuracy: 0.1117\n",
            "Epoch 35/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 562683520.0000 - position_1_1_accuracy: 0.1113 - position_1_2_accuracy: 0.1129 - position_1_3_accuracy: 0.1095 - position_1_4_accuracy: 0.1103 - position_1_5_accuracy: 0.1106 - position_1_6_accuracy: 0.1118 - position_1_7_accuracy: 0.1112 - position_1_8_accuracy: 0.1121 - position_1_9_accuracy: 0.1106 - val_loss: 291369920.0000 - val_position_1_1_accuracy: 0.1140 - val_position_1_2_accuracy: 0.1130 - val_position_1_3_accuracy: 0.1089 - val_position_1_4_accuracy: 0.1101 - val_position_1_5_accuracy: 0.1126 - val_position_1_6_accuracy: 0.1112 - val_position_1_7_accuracy: 0.1132 - val_position_1_8_accuracy: 0.1119 - val_position_1_9_accuracy: 0.1082\n",
            "Epoch 36/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 596930560.0000 - position_1_1_accuracy: 0.1120 - position_1_2_accuracy: 0.1108 - position_1_3_accuracy: 0.1108 - position_1_4_accuracy: 0.1099 - position_1_5_accuracy: 0.1111 - position_1_6_accuracy: 0.1109 - position_1_7_accuracy: 0.1104 - position_1_8_accuracy: 0.1129 - position_1_9_accuracy: 0.1117 - val_loss: 325871136.0000 - val_position_1_1_accuracy: 0.1100 - val_position_1_2_accuracy: 0.1103 - val_position_1_3_accuracy: 0.1089 - val_position_1_4_accuracy: 0.1112 - val_position_1_5_accuracy: 0.0898 - val_position_1_6_accuracy: 0.1104 - val_position_1_7_accuracy: 0.1099 - val_position_1_8_accuracy: 0.1138 - val_position_1_9_accuracy: 0.1092\n",
            "Epoch 37/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 627573376.0000 - position_1_1_accuracy: 0.1105 - position_1_2_accuracy: 0.1127 - position_1_3_accuracy: 0.1121 - position_1_4_accuracy: 0.1107 - position_1_5_accuracy: 0.1110 - position_1_6_accuracy: 0.1123 - position_1_7_accuracy: 0.1095 - position_1_8_accuracy: 0.1089 - position_1_9_accuracy: 0.1108 - val_loss: 247413792.0000 - val_position_1_1_accuracy: 0.1053 - val_position_1_2_accuracy: 0.1046 - val_position_1_3_accuracy: 0.1103 - val_position_1_4_accuracy: 0.1127 - val_position_1_5_accuracy: 0.1107 - val_position_1_6_accuracy: 0.1035 - val_position_1_7_accuracy: 0.1120 - val_position_1_8_accuracy: 0.1072 - val_position_1_9_accuracy: 0.1117\n",
            "Epoch 38/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 660375552.0000 - position_1_1_accuracy: 0.1114 - position_1_2_accuracy: 0.1106 - position_1_3_accuracy: 0.1103 - position_1_4_accuracy: 0.1129 - position_1_5_accuracy: 0.1100 - position_1_6_accuracy: 0.1102 - position_1_7_accuracy: 0.1120 - position_1_8_accuracy: 0.1108 - position_1_9_accuracy: 0.1103 - val_loss: 364540288.0000 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1129 - val_position_1_3_accuracy: 0.1112 - val_position_1_4_accuracy: 0.1131 - val_position_1_5_accuracy: 0.1129 - val_position_1_6_accuracy: 0.1112 - val_position_1_7_accuracy: 0.1099 - val_position_1_8_accuracy: 0.1118 - val_position_1_9_accuracy: 0.1148\n",
            "Epoch 39/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 692628160.0000 - position_1_1_accuracy: 0.1108 - position_1_2_accuracy: 0.1113 - position_1_3_accuracy: 0.1121 - position_1_4_accuracy: 0.1111 - position_1_5_accuracy: 0.1088 - position_1_6_accuracy: 0.1118 - position_1_7_accuracy: 0.1114 - position_1_8_accuracy: 0.1109 - position_1_9_accuracy: 0.1105 - val_loss: 366171520.0000 - val_position_1_1_accuracy: 0.1140 - val_position_1_2_accuracy: 0.1044 - val_position_1_3_accuracy: 0.1117 - val_position_1_4_accuracy: 0.1077 - val_position_1_5_accuracy: 0.1142 - val_position_1_6_accuracy: 0.1132 - val_position_1_7_accuracy: 0.1083 - val_position_1_8_accuracy: 0.1125 - val_position_1_9_accuracy: 0.1108\n",
            "Epoch 40/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 7ms/step - loss: 728662464.0000 - position_1_1_accuracy: 0.1107 - position_1_2_accuracy: 0.1119 - position_1_3_accuracy: 0.1102 - position_1_4_accuracy: 0.1113 - position_1_5_accuracy: 0.1117 - position_1_6_accuracy: 0.1126 - position_1_7_accuracy: 0.1115 - position_1_8_accuracy: 0.1112 - position_1_9_accuracy: 0.1108 - val_loss: 316667488.0000 - val_position_1_1_accuracy: 0.1151 - val_position_1_2_accuracy: 0.1044 - val_position_1_3_accuracy: 0.1117 - val_position_1_4_accuracy: 0.1119 - val_position_1_5_accuracy: 0.1099 - val_position_1_6_accuracy: 0.1104 - val_position_1_7_accuracy: 0.1212 - val_position_1_8_accuracy: 0.1126 - val_position_1_9_accuracy: 0.1113\n",
            "Epoch 41/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 758849280.0000 - position_1_1_accuracy: 0.1118 - position_1_2_accuracy: 0.1112 - position_1_3_accuracy: 0.1114 - position_1_4_accuracy: 0.1116 - position_1_5_accuracy: 0.1131 - position_1_6_accuracy: 0.1123 - position_1_7_accuracy: 0.1100 - position_1_8_accuracy: 0.1099 - position_1_9_accuracy: 0.1110 - val_loss: 314067168.0000 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1158 - val_position_1_3_accuracy: 0.1095 - val_position_1_4_accuracy: 0.1134 - val_position_1_5_accuracy: 0.1099 - val_position_1_6_accuracy: 0.1124 - val_position_1_7_accuracy: 0.1128 - val_position_1_8_accuracy: 0.1095 - val_position_1_9_accuracy: 0.1092\n",
            "Epoch 42/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - loss: 795179584.0000 - position_1_1_accuracy: 0.1122 - position_1_2_accuracy: 0.1132 - position_1_3_accuracy: 0.1109 - position_1_4_accuracy: 0.1103 - position_1_5_accuracy: 0.1119 - position_1_6_accuracy: 0.1110 - position_1_7_accuracy: 0.1098 - position_1_8_accuracy: 0.1135 - position_1_9_accuracy: 0.1114 - val_loss: 462703616.0000 - val_position_1_1_accuracy: 0.1140 - val_position_1_2_accuracy: 0.1103 - val_position_1_3_accuracy: 0.1120 - val_position_1_4_accuracy: 0.1112 - val_position_1_5_accuracy: 0.1130 - val_position_1_6_accuracy: 0.1132 - val_position_1_7_accuracy: 0.1130 - val_position_1_8_accuracy: 0.1119 - val_position_1_9_accuracy: 0.1128\n",
            "Epoch 43/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 7ms/step - loss: 832038656.0000 - position_1_1_accuracy: 0.1105 - position_1_2_accuracy: 0.1112 - position_1_3_accuracy: 0.1132 - position_1_4_accuracy: 0.1104 - position_1_5_accuracy: 0.1107 - position_1_6_accuracy: 0.1118 - position_1_7_accuracy: 0.1100 - position_1_8_accuracy: 0.1129 - position_1_9_accuracy: 0.1103 - val_loss: 458387104.0000 - val_position_1_1_accuracy: 0.1147 - val_position_1_2_accuracy: 0.1103 - val_position_1_3_accuracy: 0.1108 - val_position_1_4_accuracy: 0.1063 - val_position_1_5_accuracy: 0.1099 - val_position_1_6_accuracy: 0.1129 - val_position_1_7_accuracy: 0.1099 - val_position_1_8_accuracy: 0.1118 - val_position_1_9_accuracy: 0.1190\n",
            "Epoch 44/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 866778688.0000 - position_1_1_accuracy: 0.1113 - position_1_2_accuracy: 0.1110 - position_1_3_accuracy: 0.1097 - position_1_4_accuracy: 0.1130 - position_1_5_accuracy: 0.1126 - position_1_6_accuracy: 0.1102 - position_1_7_accuracy: 0.1120 - position_1_8_accuracy: 0.1107 - position_1_9_accuracy: 0.1123 - val_loss: 383106464.0000 - val_position_1_1_accuracy: 0.1072 - val_position_1_2_accuracy: 0.1082 - val_position_1_3_accuracy: 0.1120 - val_position_1_4_accuracy: 0.1131 - val_position_1_5_accuracy: 0.1098 - val_position_1_6_accuracy: 0.1112 - val_position_1_7_accuracy: 0.1081 - val_position_1_8_accuracy: 0.1102 - val_position_1_9_accuracy: 0.1105\n",
            "Epoch 45/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 902722688.0000 - position_1_1_accuracy: 0.1109 - position_1_2_accuracy: 0.1105 - position_1_3_accuracy: 0.1123 - position_1_4_accuracy: 0.1123 - position_1_5_accuracy: 0.1099 - position_1_6_accuracy: 0.1101 - position_1_7_accuracy: 0.1115 - position_1_8_accuracy: 0.1115 - position_1_9_accuracy: 0.1117 - val_loss: 501150272.0000 - val_position_1_1_accuracy: 0.1148 - val_position_1_2_accuracy: 0.1130 - val_position_1_3_accuracy: 0.1132 - val_position_1_4_accuracy: 0.1050 - val_position_1_5_accuracy: 0.1130 - val_position_1_6_accuracy: 0.1064 - val_position_1_7_accuracy: 0.1081 - val_position_1_8_accuracy: 0.1118 - val_position_1_9_accuracy: 0.1104\n",
            "Epoch 46/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 946116800.0000 - position_1_1_accuracy: 0.1102 - position_1_2_accuracy: 0.1102 - position_1_3_accuracy: 0.1076 - position_1_4_accuracy: 0.1112 - position_1_5_accuracy: 0.1112 - position_1_6_accuracy: 0.1111 - position_1_7_accuracy: 0.1107 - position_1_8_accuracy: 0.1130 - position_1_9_accuracy: 0.1109 - val_loss: 452750336.0000 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1147 - val_position_1_3_accuracy: 0.1132 - val_position_1_4_accuracy: 0.1114 - val_position_1_5_accuracy: 0.1118 - val_position_1_6_accuracy: 0.1104 - val_position_1_7_accuracy: 0.1115 - val_position_1_8_accuracy: 0.1103 - val_position_1_9_accuracy: 0.1090\n",
            "Epoch 47/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 981538304.0000 - position_1_1_accuracy: 0.1106 - position_1_2_accuracy: 0.1096 - position_1_3_accuracy: 0.1108 - position_1_4_accuracy: 0.1110 - position_1_5_accuracy: 0.1103 - position_1_6_accuracy: 0.1117 - position_1_7_accuracy: 0.1110 - position_1_8_accuracy: 0.1103 - position_1_9_accuracy: 0.1127 - val_loss: 457734688.0000 - val_position_1_1_accuracy: 0.1108 - val_position_1_2_accuracy: 0.1106 - val_position_1_3_accuracy: 0.1098 - val_position_1_4_accuracy: 0.1134 - val_position_1_5_accuracy: 0.1099 - val_position_1_6_accuracy: 0.1118 - val_position_1_7_accuracy: 0.1130 - val_position_1_8_accuracy: 0.1109 - val_position_1_9_accuracy: 0.1104\n",
            "Epoch 48/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 1020746688.0000 - position_1_1_accuracy: 0.1124 - position_1_2_accuracy: 0.1093 - position_1_3_accuracy: 0.1123 - position_1_4_accuracy: 0.1126 - position_1_5_accuracy: 0.1118 - position_1_6_accuracy: 0.1119 - position_1_7_accuracy: 0.1114 - position_1_8_accuracy: 0.1116 - position_1_9_accuracy: 0.1096 - val_loss: 540478720.0000 - val_position_1_1_accuracy: 0.1106 - val_position_1_2_accuracy: 0.1150 - val_position_1_3_accuracy: 0.1106 - val_position_1_4_accuracy: 0.1105 - val_position_1_5_accuracy: 0.1101 - val_position_1_6_accuracy: 0.1129 - val_position_1_7_accuracy: 0.1141 - val_position_1_8_accuracy: 0.1126 - val_position_1_9_accuracy: 0.1105\n",
            "Epoch 49/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 1057308544.0000 - position_1_1_accuracy: 0.1112 - position_1_2_accuracy: 0.1118 - position_1_3_accuracy: 0.1111 - position_1_4_accuracy: 0.1100 - position_1_5_accuracy: 0.1119 - position_1_6_accuracy: 0.1119 - position_1_7_accuracy: 0.1133 - position_1_8_accuracy: 0.1091 - position_1_9_accuracy: 0.1121 - val_loss: 481813984.0000 - val_position_1_1_accuracy: 0.1098 - val_position_1_2_accuracy: 0.1147 - val_position_1_3_accuracy: 0.1108 - val_position_1_4_accuracy: 0.1101 - val_position_1_5_accuracy: 0.1100 - val_position_1_6_accuracy: 0.1088 - val_position_1_7_accuracy: 0.1072 - val_position_1_8_accuracy: 0.1126 - val_position_1_9_accuracy: 0.1092\n",
            "Epoch 50/50\n",
            "\u001b[1m2667/2667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 1102434560.0000 - position_1_1_accuracy: 0.1109 - position_1_2_accuracy: 0.1111 - position_1_3_accuracy: 0.1101 - position_1_4_accuracy: 0.1129 - position_1_5_accuracy: 0.1098 - position_1_6_accuracy: 0.1108 - position_1_7_accuracy: 0.1123 - position_1_8_accuracy: 0.1122 - position_1_9_accuracy: 0.1094 - val_loss: 488589952.0000 - val_position_1_1_accuracy: 0.1130 - val_position_1_2_accuracy: 0.1130 - val_position_1_3_accuracy: 0.1093 - val_position_1_4_accuracy: 0.1095 - val_position_1_5_accuracy: 0.1107 - val_position_1_6_accuracy: 0.1132 - val_position_1_7_accuracy: 0.1133 - val_position_1_8_accuracy: 0.1125 - val_position_1_9_accuracy: 0.1125\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 488540032.0000 - position_1_1_accuracy: 0.1116 - position_1_2_accuracy: 0.1100 - position_1_3_accuracy: 0.1068 - position_1_4_accuracy: 0.1120 - position_1_5_accuracy: 0.1132 - position_1_6_accuracy: 0.1118 - position_1_7_accuracy: 0.1126 - position_1_8_accuracy: 0.1112 - position_1_9_accuracy: 0.1103\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the model architecture\n",
        "def build_model():\n",
        "    model_input = layers.Input(shape=(9, 9, 10), name=\"puzzle\")\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"block_01_linear\")(model_input)\n",
        "    x = layers.Dropout(0.4, name=\"block_01_dopout\")(x)\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"block_02_linear\")(x)\n",
        "    x = layers.Dropout(0.4, name=\"block_02_dropout\")(x)\n",
        "    x = layers.Flatten(name=\"flatten\")(x)\n",
        "    model_output = [\n",
        "        layers.Dense(9, activation=\"softmax\", name=f\"position_{i+1}_{j+1}\")(x) for i in range(9) for j in range(9)\n",
        "    ]\n",
        "\n",
        "    model = models.Model(\n",
        "        inputs=model_input,\n",
        "        outputs=[model_output[i * 9 + j] for i in range(9) for j in range(9)],\n",
        "        name=\"SuDoKuNetFFN\",\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "model = build_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\", # Optimizer\n",
        "    loss=[\"categorical_crossentropy\"]*81,\n",
        "    metrics=[[\"accuracy\"]]*81\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train,\n",
        "    [y_train[:, i*9:(i+1)*9] for i in range(9)],\n",
        "    epochs=50, # Number of epochs\n",
        "    batch_size=81, # Number of samples per gradient update\n",
        "    validation_split=0.1 # Fraction of the training data to be used as validation data\n",
        ")\n",
        "\n",
        "score = model.evaluate(\n",
        "    X_test,\n",
        "    [y_test[:, i*9:(i+1)*9] for i in range(9)]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "aRobDgqtxHmM"
      },
      "outputs": [],
      "source": [
        "model.save('ffn_model.keras') # Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WjbYab2gdTA",
        "outputId": "d6b8792d-e130-49e4-a2f3-de203a21e74b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Case #1:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "Failed. Expected 534678912672195348198342567859761423426853791713924856961537284287419635345286179, but got 442886912625674682942434684693424316516911954971218646137386522685752866655756352\n",
            "\n",
            "Test Case #2:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Failed. Expected 987654321246173985351928746128537694634892157795461832519286473472319568863745219, but got 462588919925674992942334944918314316216511954431268684137586422545752866655732352\n",
            "\n",
            "Test Case #3:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Failed. Expected 123456789456789123789123456214365897365897214897214365531642978642978531978531642, but got 472983917915674692945334944298344316516511954837268684747886522545752866655752352\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Simple test function \n",
        "def test_solver():\n",
        "    # Define some test cases\n",
        "    test_cases = [\n",
        "        {\n",
        "            \"puzzle\": \"530070000600195000098000060800060003400803001700020006060000280000419005000080079\",\n",
        "            \"solution\": \"534678912672195348198342567859761423426853791713924856961537284287419635345286179\"\n",
        "        },\n",
        "        {\n",
        "            \"puzzle\": \"000000000000003085001020000000507000004000100090000000500000073002010000000040009\",\n",
        "            \"solution\": \"987654321246173985351928746128537694634892157795461832519286473472319568863745219\"\n",
        "        },\n",
        "        {\n",
        "            \"puzzle\": \"000000000000000000000000000000000000000000000000000000000000000000000000000000000\",\n",
        "            \"solution\": \"123456789456789123789123456214365897365897214897214365531642978642978531978531642\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Iterate over test cases\n",
        "    for i, case in enumerate(test_cases):\n",
        "        print(f\"Test Case #{i+1}:\")\n",
        "\n",
        "        # Prepare input data\n",
        "        test_input = np.array(list(map(int, case['puzzle']))).reshape(1, 9, 9, 1)\n",
        "        test_input = np.eye(10)[test_input.reshape(-1).astype(int)].reshape(test_input.shape[0], 9, 9, 10)\n",
        "\n",
        "        # Get model's prediction\n",
        "        prediction = model.predict(test_input)\n",
        "        predicted_solution = \"\".join(str(np.argmax(pos)+1) for pos_row in prediction for pos in pos_row)\n",
        "\n",
        "        # Compare with expected solution\n",
        "        expected_solution = case['solution']\n",
        "        if predicted_solution == expected_solution:\n",
        "            print(\"Passed!\")\n",
        "        else:\n",
        "            print(f\"Failed. Expected {expected_solution}, but got {predicted_solution}\")\n",
        "\n",
        "        print()\n",
        "\n",
        "# Run the tests\n",
        "test_solver()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
