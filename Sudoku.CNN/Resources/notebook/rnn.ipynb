{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9888cceb-a5ff-4ca0-9c4c-78bb4ad96d9c",
   "metadata": {},
   "source": [
    "Notebook created to build and evaluate a RNN model for solving sudoku problems.\n",
    "Be sure to get the dataset from https://www.kaggle.com/datasets/radcliffe/3-million-sudoku-puzzles-with-ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68b76485-970c-465f-b0b0-e688921fbaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Imports needed\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e7d1090-82c1-4215-8da2-e1253025c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create Sudoku datasets from a DataFrame\n",
    "def create_sudoku_tensors(df, train_split=0.5):\n",
    "    # Total number of samples in the DataFrame\n",
    "    s = df.shape[0]\n",
    "\n",
    "    # Function to one-hot encode a Sudoku puzzle\n",
    "    def one_hot_encode(s):\n",
    "        zeros = torch.zeros((1, 81, 9), dtype=torch.float)\n",
    "        for a in range(81):\n",
    "            digit = s[a]\n",
    "            # Check if the character is a digit\n",
    "            if digit.isdigit():\n",
    "                # One-hot encode the digit\n",
    "                zeros[0, a, int(digit) - 1] = 1 if int(digit) > 0 else 0\n",
    "        return zeros\n",
    "\n",
    "    # Apply one-hot encoding to puzzle and solution columns\n",
    "    quizzes_t = df.puzzle.apply(one_hot_encode)\n",
    "    solutions_t = df.solution.apply(one_hot_encode)\n",
    "\n",
    "    # Concatenate tensors and split into training and test sets\n",
    "    quizzes_t = torch.cat(quizzes_t.values.tolist())\n",
    "    solutions_t = torch.cat(solutions_t.values.tolist())\n",
    "    randperm = torch.randperm(s)\n",
    "    train = randperm[:int(train_split * s)]\n",
    "    test = randperm[int(train_split * s):]\n",
    "\n",
    "    return data.TensorDataset(quizzes_t[train], solutions_t[train]), \\\n",
    "           data.TensorDataset(quizzes_t[test], solutions_t[test])\n",
    "\n",
    "\n",
    "# Function to create a constraint mask for Sudoku puzzles\n",
    "def create_constraint_mask():\n",
    "    constraint_mask = torch.zeros((81, 3, 81), dtype=torch.float)\n",
    "\n",
    "    # Row constraints\n",
    "    for a in range(81):\n",
    "        r = 9 * (a // 9)\n",
    "        for b in range(9):\n",
    "            constraint_mask[a, 0, r + b] = 1\n",
    "\n",
    "    # Column constraints\n",
    "    for a in range(81):\n",
    "        c = a % 9\n",
    "        for b in range(9):\n",
    "            constraint_mask[a, 1, c + 9 * b] = 1\n",
    "\n",
    "    # Box constraints\n",
    "    for a in range(81):\n",
    "        r = a // 9\n",
    "        c = a % 9\n",
    "        br = 3 * 9 * (r // 3)\n",
    "        bc = 3 * (c // 3)\n",
    "        for b in range(9):\n",
    "            r = b % 3\n",
    "            c = 9 * (b // 3)\n",
    "            constraint_mask[a, 2, br + bc + r + c] = 1\n",
    "\n",
    "    return constraint_mask\n",
    "\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_dataset(subsample=10000):\n",
    "    dataset = pd.read_csv(\"sudoku-3m.csv\", sep=',')\n",
    "    my_sample = dataset.sample(subsample)\n",
    "    train_set, test_set = create_sudoku_tensors(my_sample)\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9df66b7d-b8e8-4899-a073-522f6eb5a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SudokuSolver model\n",
    "class SudokuSolver(nn.Module):\n",
    "    def __init__(self, constraint_mask, n=9, hidden1=100):\n",
    "        super(SudokuSolver, self).__init__()\n",
    "        self.constraint_mask = constraint_mask.view(1, n * n, 3, n * n, 1)\n",
    "        self.n = n\n",
    "        self.hidden1 = hidden1\n",
    "\n",
    "        # Feature vector is the 3 constraints\n",
    "        self.input_size = 3 * n\n",
    "\n",
    "        # Define the neural network layers\n",
    "        self.l1 = nn.Linear(self.input_size, self.hidden1, bias=False)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.l2 = nn.Linear(self.hidden1, n, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    # Forward pass of the model\n",
    "    def forward(self, x):\n",
    "        n = self.n\n",
    "        bts = x.shape[0]\n",
    "        c = self.constraint_mask\n",
    "        min_empty = (x.sum(dim=2) == 0).sum(dim=1).max()\n",
    "        x_pred = x.clone()\n",
    "        for a in range(min_empty):\n",
    "            # Score empty numbers\n",
    "            constraints = (x.view(bts, 1, 1, n * n, n) * c).sum(dim=3)\n",
    "            # Empty cells\n",
    "            empty_mask = (x.sum(dim=2) == 0)\n",
    "\n",
    "            f = constraints.reshape(bts, n * n, 3 * n)\n",
    "            y_ = self.l2(self.a1(self.l1(f[empty_mask])))\n",
    "\n",
    "            s_ = self.softmax(y_)\n",
    "\n",
    "            # Score the rows\n",
    "            x_pred[empty_mask] = s_\n",
    "\n",
    "            s = torch.zeros_like(x_pred)\n",
    "            s[empty_mask] = s_\n",
    "            # Find most probable guess\n",
    "            score, score_pos = s.max(dim=2)\n",
    "            mmax = score.max(dim=1)[1]\n",
    "            # Fill it in\n",
    "            nz = empty_mask.sum(dim=1).nonzero().view(-1)\n",
    "            mmax_ = mmax[nz]\n",
    "            ones = torch.ones(nz.shape[0])\n",
    "            x.index_put_((nz, mmax_, score_pos[nz, mmax_]), ones)\n",
    "        return x_pred, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "250fe7ba-9318-40b2-a99a-bf4a1225e772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Validation Accuracy: 58.403950617283954%\n",
      "Epoch 1: Validation Accuracy: 59.58172839506173%\n",
      "Epoch 2: Validation Accuracy: 58.8279012345679%\n",
      "Epoch 3: Validation Accuracy: 58.821728395061726%\n",
      "Epoch 4: Validation Accuracy: 58.98493827160494%\n",
      "Epoch 5: Validation Accuracy: 59.77185185185186%\n",
      "Epoch 6: Validation Accuracy: 59.181975308641974%\n",
      "Epoch 7: Validation Accuracy: 60.026172839506174%\n",
      "Epoch 8: Validation Accuracy: 60.52864197530864%\n",
      "Epoch 9: Validation Accuracy: 60.309382716049384%\n",
      "Epoch 10: Validation Accuracy: 59.7879012345679%\n",
      "Epoch 11: Validation Accuracy: 59.55802469135803%\n",
      "Epoch 12: Validation Accuracy: 60.46691358024692%\n",
      "Epoch 13: Validation Accuracy: 60.67086419753086%\n",
      "Epoch 14: Validation Accuracy: 59.95456790123457%\n",
      "Epoch 15: Validation Accuracy: 60.4641975308642%\n",
      "Epoch 16: Validation Accuracy: 61.01753086419753%\n",
      "Epoch 17: Validation Accuracy: 60.8232098765432%\n",
      "Epoch 18: Validation Accuracy: 60.95901234567901%\n",
      "Epoch 19: Validation Accuracy: 61.86962962962963%\n",
      "Epoch 20: Validation Accuracy: 60.833827160493826%\n",
      "Epoch 21: Validation Accuracy: 63.32864197530864%\n",
      "Epoch 22: Validation Accuracy: 60.50888888888889%\n",
      "Epoch 23: Validation Accuracy: 60.741728395061735%\n",
      "Epoch 24: Validation Accuracy: 62.66641975308642%\n",
      "Epoch 25: Validation Accuracy: 60.678271604938274%\n",
      "Epoch 26: Validation Accuracy: 61.86493827160494%\n",
      "Epoch 27: Validation Accuracy: 60.766666666666666%\n",
      "Epoch 28: Validation Accuracy: 61.73135802469136%\n",
      "Epoch 29: Validation Accuracy: 60.99061728395062%\n",
      "Epoch 30: Validation Accuracy: 61.465432098765426%\n",
      "Epoch 31: Validation Accuracy: 61.58765432098765%\n",
      "Epoch 32: Validation Accuracy: 61.80765432098766%\n",
      "Epoch 33: Validation Accuracy: 60.41654320987654%\n",
      "Epoch 34: Validation Accuracy: 62.55407407407407%\n",
      "Epoch 35: Validation Accuracy: 60.744938271604944%\n",
      "Epoch 36: Validation Accuracy: 61.227654320987654%\n",
      "Epoch 37: Validation Accuracy: 61.21925925925926%\n",
      "Epoch 38: Validation Accuracy: 60.94913580246914%\n",
      "Epoch 39: Validation Accuracy: 60.57283950617284%\n",
      "Epoch 40: Validation Accuracy: 63.385925925925925%\n",
      "Epoch 41: Validation Accuracy: 61.41037037037037%\n",
      "Epoch 42: Validation Accuracy: 62.34765432098766%\n",
      "Epoch 43: Validation Accuracy: 63.45703703703703%\n",
      "Epoch 44: Validation Accuracy: 60.568395061728395%\n",
      "Epoch 45: Validation Accuracy: 63.29012345679013%\n",
      "Epoch 46: Validation Accuracy: 61.56469135802469%\n",
      "Epoch 47: Validation Accuracy: 60.0437037037037%\n",
      "Epoch 48: Validation Accuracy: 61.973580246913585%\n",
      "Epoch 49: Validation Accuracy: 62.804197530864194%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "# Batch size for training\n",
    "batch_size = 20\n",
    "\n",
    "# Load the dataset\n",
    "train_set, test_set = load_dataset()\n",
    "\n",
    "# Create constraint mask\n",
    "constraint_mask = create_constraint_mask()\n",
    "\n",
    "# Create data loaders for training and validation\n",
    "dataloader_ = data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val_ = data.DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define loss function\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# Initialize the SudokuSolver model\n",
    "sudoku_solver = SudokuSolver(constraint_mask)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(sudoku_solver.parameters(), lr=0.01, weight_decay=0.000)\n",
    "\n",
    "# Number of epochs for training\n",
    "epochs = 50\n",
    "\n",
    "# Lists to store training and validation losses\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "\n",
    "# Training loop\n",
    "for e in range(epochs):\n",
    "    total_correct_cells = 0\n",
    "    total_cells = 0\n",
    "    for i_batch, ts_ in enumerate(dataloader_):\n",
    "        sudoku_solver.train()\n",
    "        optimizer.zero_grad()\n",
    "        pred, mat = sudoku_solver(ts_[0])\n",
    "        ls = loss(pred, ts_[1])\n",
    "        ls.backward()\n",
    "        optimizer.step()\n",
    "        loss_train.append(ls.item())\n",
    "        \n",
    "        # Calculate accuracy during training\n",
    "        correct_cells = (pred.argmax(dim=2) == ts_[1].argmax(dim=2)).sum().item()\n",
    "        total_correct_cells += correct_cells\n",
    "        total_cells += ts_[1].size(0) * ts_[1].size(1)\n",
    "        \n",
    "    # Calculate validation accuracy after each epoch\n",
    "    sudoku_solver.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_correct_cells = 0\n",
    "        total_val_cells = 0\n",
    "        for i_batch, ts_ in enumerate(dataloader_val_):\n",
    "            test_pred, test_fill = sudoku_solver(ts_[0])\n",
    "            val_correct_cells = (test_pred.argmax(dim=2) == ts_[1].argmax(dim=2)).sum().item()\n",
    "            total_val_correct_cells += val_correct_cells\n",
    "            total_val_cells += ts_[1].size(0) * ts_[1].size(1)\n",
    "            \n",
    "        accuracy_val = total_val_correct_cells / total_val_cells * 100\n",
    "        loss_val.append(accuracy_val)\n",
    "        \n",
    "        print(f\"Epoch {e}: Validation Accuracy: {accuracy_val}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ab65f30-564a-49ca-ab8b-f0d842c4bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sudoku_solver.state_dict(), \"rnn_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-max",
   "language": "python",
   "name": "max"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
